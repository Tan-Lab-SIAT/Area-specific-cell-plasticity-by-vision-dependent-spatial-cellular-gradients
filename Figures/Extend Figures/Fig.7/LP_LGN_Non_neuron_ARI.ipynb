{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ce0c2b-e8dc-4296-9b5b-499121dae263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, adjusted_rand_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cbd560-03d2-4f3e-8157-ebc2affbae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateNCE(labels_true,labels_pred):\n",
    "    X = labels_true\n",
    "    Y = labels_pred\n",
    "    contTable = confusion_matrix(X,Y)[0:len(np.unique(X)), 0:len(np.unique(Y))]\n",
    "    a = np.sum(contTable, axis = 1)\n",
    "    b = np.sum(contTable, axis = 0)\n",
    "    N = np.sum(contTable)\n",
    "    pij = contTable/N\n",
    "    pi = a/N\n",
    "    pj = b/N\n",
    "    Hyx = np.zeros(contTable.shape)\n",
    "    for i in range(contTable.shape[0]):\n",
    "        for j in range(contTable.shape[1]):\n",
    "          if pij[i,j] == 0:\n",
    "            Hyx[i,j] = 0\n",
    "          else:\n",
    "            Hyx[i,j] = pij[i,j]*np.log10(pij[i,j]/pi[i])\n",
    "    CE = -np.sum(Hyx)\n",
    "    Hyi = np.zeros(contTable.shape[1])\n",
    "    for j in range(contTable.shape[1]):\n",
    "      if pj[j] == 0:\n",
    "       Hyi[j] = 0\n",
    "      else:\n",
    "        Hyi[j] = pj[j]*np.log10(pj[j])\n",
    "    Hy = -np.sum(Hyi)\n",
    "    NCE = CE/Hy\n",
    "    return NCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd1849-e641-412c-b207-f882c03165ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining class that contains functions that will perform the mapping with XGBoost and plot the results\n",
    "class TimeMapping():\n",
    "    # xgbclassifier will run the feature selection, training and validation, and testing\n",
    "    def xgbclassifier(\n",
    "            self,\n",
    "            train_anndata,\n",
    "            test_anndata,\n",
    "            train_dict,\n",
    "            test_dict,\n",
    "            max_cells_per_ident=700,\n",
    "            train_frac=0.7\n",
    "    ):\n",
    "\n",
    "        self.train_dict = train_dict\n",
    "        self.test_dict = test_dict\n",
    "\n",
    "        self.numbertrainclasses = len(train_anndata.obs.cluster.values.categories)\n",
    "        self.numbertestclasses = len(test_anndata.obs.cluster.values.categories)\n",
    "\n",
    "        # Splitting the cell barcodes into a training set and validation set based on the minimum of 70% of cells or 700 cells\n",
    "        # Creating array of the labels for each cell (the cluster each cell barcode belongs too)\n",
    "        training_set_train = []\n",
    "        training_label_train = []\n",
    "\n",
    "        for i in train_anndata.obs.cluster.values.categories.values:\n",
    "            cells_in_clust = train_anndata.obs.index[train_anndata.obs.cluster.values == i]\n",
    "            n = min(max_cells_per_ident, round(len(cells_in_clust) * train_frac))\n",
    "            train_temp = np.random.choice(cells_in_clust, n, replace=False)\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size=100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_train = np.hstack([training_set_train, train_temp])\n",
    "            training_label_train = np.hstack([training_label_train, np.repeat(train_dict[i], len(train_temp))])\n",
    "\n",
    "        training_set_test = []\n",
    "        training_label_test = []\n",
    "        for i in test_anndata.obs.cluster.values.categories.values:\n",
    "            cells_in_clust = test_anndata.obs.index[test_anndata.obs.cluster.values == i]\n",
    "            n = min(max_cells_per_ident, round(len(cells_in_clust) * train_frac))\n",
    "            train_temp = np.random.choice(cells_in_clust, n, replace=False)\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size=100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_test = np.hstack([training_set_test, train_temp])\n",
    "            training_label_test = np.hstack([training_label_test, np.repeat(test_dict[i], len(train_temp))])\n",
    "\n",
    "        train_index_train = []\n",
    "        for i in training_set_train:\n",
    "            train_index_train.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        train_index_test = []\n",
    "        for i in training_set_test:\n",
    "            train_index_test.append(np.where(test_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        train_matrix_train = xgb.DMatrix(data=train_anndata.X[train_index_train, :], label=training_label_train,\n",
    "                                         feature_names=list(train_anndata.var.index.values))\n",
    "\n",
    "        train_matrix_test = xgb.DMatrix(data=test_anndata.X[train_index_test, :], label=training_label_test,\n",
    "                                        feature_names=list(test_anndata.var.index.values))\n",
    "\n",
    "        del training_set_train, training_label_train, training_set_test, training_label_test, train_index_train, train_index_test\n",
    "\n",
    "        # Defining parameters for the XGBoost Model\n",
    "        xgb_params_train = {\n",
    "            'objective': 'multi:softprob',\n",
    "            'eval_metric': 'mlogloss',\n",
    "            'num_class': self.numbertrainclasses,\n",
    "            'eta': 0.2,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.6}\n",
    "        nround = 200\n",
    "\n",
    "        # Fitting the XGBoost Model to the training data\n",
    "        bst_model_train = xgb.train(\n",
    "            params=xgb_params_train,\n",
    "            dtrain=train_matrix_train,\n",
    "            num_boost_round=nround)\n",
    "\n",
    "        xgb_params_test = {\n",
    "            'objective': 'multi:softprob',\n",
    "            'eval_metric': 'mlogloss',\n",
    "            'num_class': self.numbertestclasses,\n",
    "            'eta': 0.2,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.6}\n",
    "        nround = 200\n",
    "\n",
    "        # Fitting the XGBoost Model to the testing data\n",
    "        bst_model_test = xgb.train(\n",
    "            params=xgb_params_test,\n",
    "            dtrain=train_matrix_test,\n",
    "            num_boost_round=nround)\n",
    "        train_xgboost_scores = bst_model_train.get_score(importance_type=\"gain\")\n",
    "        sort_train_scores = {k: v for k, v in\n",
    "                             sorted(train_xgboost_scores.items(), key=lambda item: item[1], reverse=True)[:500]}\n",
    "        top500genestrain = list(sort_train_scores.keys())\n",
    "\n",
    "        test_xgboost_scores = bst_model_test.get_score(importance_type=\"gain\")\n",
    "        sort_test_scores = {k: v for k, v in\n",
    "                            sorted(test_xgboost_scores.items(), key=lambda item: item[1], reverse=True)[:500]}\n",
    "        top500genestest = list(sort_test_scores.keys())\n",
    "\n",
    "        common_top_genes = np.array([i for i in top500genestrain if\n",
    "                                     i in top500genestest])  # These are the features that we will use for training, validating and testing\n",
    "\n",
    "        del train_matrix_train, train_matrix_test, bst_model_train, bst_model_test, train_xgboost_scores, sort_train_scores, top500genestrain, test_xgboost_scores, sort_test_scores, top500genestest\n",
    "\n",
    "        # Train XGBoost on 70% of training data and validate on the remaining data\n",
    "        common_top_genes_index_train = []\n",
    "        for i in common_top_genes:\n",
    "            common_top_genes_index_train.append(np.where(train_anndata.var.index.values == i)[0][0])\n",
    "\n",
    "        training_set_train_70 = []\n",
    "        validation_set_train_70 = []\n",
    "        training_label_train_70 = []\n",
    "        validation_label_train_70 = []\n",
    "\n",
    "        for i in train_anndata.obs.cluster.values.categories.values:\n",
    "            cells_in_clust = train_anndata.obs.index[train_anndata.obs.cluster.values == i]\n",
    "            n = min(max_cells_per_ident, round(len(cells_in_clust) * train_frac))\n",
    "            train_temp = np.random.choice(cells_in_clust, n, replace=False)\n",
    "            validation_temp = np.setdiff1d(cells_in_clust, train_temp)\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size=100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_train_70 = np.hstack([training_set_train_70, train_temp])\n",
    "            validation_set_train_70 = np.hstack([validation_set_train_70, validation_temp])\n",
    "            training_label_train_70 = np.hstack([training_label_train_70, np.repeat(train_dict[i], len(train_temp))])\n",
    "            validation_label_train_70 = np.hstack(\n",
    "                [validation_label_train_70, np.repeat(train_dict[i], len(validation_temp))])\n",
    "        train_index_train_70 = []\n",
    "        for i in training_set_train_70:\n",
    "            train_index_train_70.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "        validation_index_train_70 = []\n",
    "        for i in validation_set_train_70:\n",
    "            validation_index_train_70.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        train_matrix_train_70 = xgb.DMatrix(\n",
    "            data=train_anndata.X[:, common_top_genes_index_train][train_index_train_70, :],\n",
    "            label=training_label_train_70)\n",
    "        validation_matrix_train_70 = xgb.DMatrix(\n",
    "            data=train_anndata.X[:, common_top_genes_index_train][validation_index_train_70, :],\n",
    "            label=validation_label_train_70)\n",
    "\n",
    "        del training_set_train_70, validation_set_train_70, training_label_train_70, train_index_train_70, validation_index_train_70\n",
    "\n",
    "        bst_model_train_70 = xgb.train(\n",
    "            params=xgb_params_train,\n",
    "            dtrain=train_matrix_train_70,\n",
    "            num_boost_round=nround)\n",
    "\n",
    "        validation_pred_train_70 = bst_model_train_70.predict(data=validation_matrix_train_70)\n",
    "\n",
    "        valid_predlabels_train_70 = np.zeros((validation_pred_train_70.shape[0]))\n",
    "        for i in range(validation_pred_train_70.shape[0]):\n",
    "            valid_predlabels_train_70[i] = np.argmax(validation_pred_train_70[i, :])\n",
    "\n",
    "        del train_matrix_train_70, validation_matrix_train_70, validation_pred_train_70\n",
    "\n",
    "        # Train XGBoost on the full training data\n",
    "        training_set_train_full = []\n",
    "        training_label_train_full = []\n",
    "\n",
    "        for i in train_anndata.obs.cluster.values.categories.values:\n",
    "            train_temp = train_anndata.obs.index[train_anndata.obs.cluster.values == i]\n",
    "            if len(train_temp) < 100:\n",
    "                train_temp_bootstrap = np.random.choice(train_temp, size=100 - int(len(train_temp)))\n",
    "                train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "            training_set_train_full = np.hstack([training_set_train_full, train_temp])\n",
    "            training_label_train_full = np.hstack(\n",
    "                [training_label_train_full, np.repeat(train_dict[i], len(train_temp))])\n",
    "\n",
    "        train_index_full = []\n",
    "        for i in training_set_train_full:\n",
    "            train_index_full.append(np.where(train_anndata.obs.index.values == i)[0][0])\n",
    "\n",
    "        full_training_data = xgb.DMatrix(\n",
    "            data=train_anndata.X[:, common_top_genes_index_train][train_index_full, :],\n",
    "            label=training_label_train_full)\n",
    "        del common_top_genes_index_train, training_set_train_full, training_label_train_full, train_index_full\n",
    "\n",
    "        bst_model_full_train = xgb.train(\n",
    "            params=xgb_params_train,\n",
    "            dtrain=full_training_data,\n",
    "            num_boost_round=nround)\n",
    "\n",
    "        # Predict the testing cluster labels\n",
    "        common_top_genes_index_test = []\n",
    "        for i in common_top_genes:\n",
    "            common_top_genes_index_test.append(np.where(test_anndata.var.index.values == i)[0][0])\n",
    "\n",
    "        full_testing_data = xgb.DMatrix(data=test_anndata.X[:, common_top_genes_index_test])\n",
    "        test_prediction = bst_model_full_train.predict(data=full_testing_data)\n",
    "\n",
    "        del bst_model_full_train, full_testing_data\n",
    "\n",
    "        test_predlabels = np.zeros((test_prediction.shape[0]))\n",
    "        for i in range(test_prediction.shape[0]):\n",
    "            if np.max(test_prediction[i, :]) > 1.1 * (1 / self.numbertrainclasses):\n",
    "                test_predlabels[i] = np.argmax(test_prediction[i, :])\n",
    "            else:\n",
    "                test_predlabels[i] = self.numbertrainclasses\n",
    "\n",
    "        test_labels = np.zeros(len(test_anndata.obs.cluster.values))\n",
    "        for i, l in enumerate(test_anndata.obs.cluster.values):\n",
    "            test_labels[i] = test_dict[l]\n",
    "\n",
    "        return validation_label_train_70, valid_predlabels_train_70, test_labels, test_predlabels\n",
    "    #plotConfusionMatrix will take the results from the xgboost classifier and plot them\n",
    "    def plotConfusionMatrix(\n",
    "        self,\n",
    "        ytrue,\n",
    "        ypred,\n",
    "        type,\n",
    "        save_as,\n",
    "        title = '',\n",
    "        xaxislabel = '',\n",
    "        yaxislabel = ''\n",
    "        ):\n",
    "\n",
    "        confusionmatrix = confusion_matrix(y_true = ytrue, y_pred = ypred)\n",
    "        if type == 'mapping':\n",
    "          if self.numbertrainclasses in ypred:\n",
    "            confusionmatrix = confusionmatrix[0:self.numbertestclasses,0:self.numbertrainclasses+1]\n",
    "          else:\n",
    "            confusionmatrix = confusionmatrix[0:self.numbertestclasses,0:self.numbertrainclasses]\n",
    "        confmatpercent = np.zeros(confusionmatrix.shape)\n",
    "        for i in range(confusionmatrix.shape[0]):\n",
    "          if np.sum(confusionmatrix[i,:]) != 0:\n",
    "            confmatpercent[i,:] = confusionmatrix[i,:]/np.sum(confusionmatrix[i,:])\n",
    "          else:\n",
    "            confmatpercent[i,:] = confusionmatrix[i,:]\n",
    "        diagcm = confmatpercent\n",
    "        xticks = np.linspace(0, confmatpercent.shape[1]-1, confmatpercent.shape[1], dtype = int)\n",
    "        xticksactual = []\n",
    "        for i in xticks:\n",
    "          if i != self.numbertrainclasses:\n",
    "            xticksactual.append(list(self.train_dict.keys())[i])\n",
    "          else:\n",
    "            xticksactual.append('Unassigned')\n",
    "        dot_max = np.max(diagcm.flatten())\n",
    "        dot_min = 0\n",
    "        if dot_min != 0 or dot_max != 1:\n",
    "            frac = np.clip(diagcm, dot_min, dot_max)\n",
    "            old_range = dot_max - dot_min\n",
    "            frac = (frac - dot_min) / old_range\n",
    "        else:\n",
    "            frac = diagcm\n",
    "        xvalues = []\n",
    "        yvalues = []\n",
    "        sizes = []\n",
    "        for i in range(diagcm.shape[0]):\n",
    "            for j in range(diagcm.shape[1]):\n",
    "                xvalues.append(j)\n",
    "                yvalues.append(i)\n",
    "                sizes.append((frac[i,j]*35)**1.5)\n",
    "        size_legend_width = 0.5\n",
    "        height = diagcm.shape[0] * 0.3 + 1\n",
    "        height = max([1.5, height])\n",
    "        heatmap_width = diagcm.shape[1] * 0.35\n",
    "        width = (\n",
    "            heatmap_width\n",
    "            + size_legend_width\n",
    "            )\n",
    "        fig = plt.figure(figsize=(width, height))\n",
    "        axs = gridspec.GridSpec(\n",
    "            nrows=2,\n",
    "            ncols=2,\n",
    "            wspace=0.02,\n",
    "            hspace=0.04,\n",
    "            width_ratios=[\n",
    "                heatmap_width,\n",
    "                size_legend_width\n",
    "            ],\n",
    "            height_ratios=[0.5, 10]\n",
    "        )\n",
    "        dot_ax = fig.add_subplot(axs[1, 0])\n",
    "        dot_ax.scatter(xvalues, yvalues, s=sizes, c='blue', norm=None, edgecolor='none')\n",
    "        y_ticks = range(diagcm.shape[0])\n",
    "        dot_ax.set_yticks(y_ticks)\n",
    "        if type == 'validation':\n",
    "            dot_ax.set_yticklabels(list(self.train_dict.keys()))\n",
    "        elif type == 'mapping':\n",
    "            dot_ax.set_yticklabels(list(self.test_dict.keys()))\n",
    "        x_ticks = range(diagcm.shape[1])\n",
    "        dot_ax.set_xticks(x_ticks)\n",
    "        dot_ax.set_xticklabels(xticksactual, rotation=90)\n",
    "        dot_ax.tick_params(axis='both', labelsize='small')\n",
    "        dot_ax.grid(True, linewidth=0.2)\n",
    "        dot_ax.set_axisbelow(True)\n",
    "        dot_ax.set_xlim(-0.5, diagcm.shape[1] + 0.5)\n",
    "        ymin, ymax = dot_ax.get_ylim()\n",
    "        dot_ax.set_ylim(ymax + 0.5, ymin - 0.5)\n",
    "        dot_ax.set_xlim(-1, diagcm.shape[1])\n",
    "        dot_ax.set_xlabel(xaxislabel)\n",
    "        dot_ax.set_ylabel(yaxislabel)\n",
    "        dot_ax.set_title(title)\n",
    "        size_legend_height = min(1.75, height)\n",
    "        wspace = 10.5 / width\n",
    "        axs3 = gridspec.GridSpecFromSubplotSpec(\n",
    "            2,\n",
    "            1,\n",
    "            subplot_spec=axs[1, 1],\n",
    "            wspace=wspace,\n",
    "            height_ratios=[\n",
    "                size_legend_height / height,\n",
    "                (height - size_legend_height) / height\n",
    "            ]\n",
    "        )\n",
    "        diff = dot_max - dot_min\n",
    "        if 0.3 < diff <= 0.6:\n",
    "            step = 0.1\n",
    "        elif diff <= 0.3:\n",
    "            step = 0.05\n",
    "        else:\n",
    "            step = 0.2\n",
    "        fracs_legends = np.arange(dot_max, dot_min, step * -1)[::-1]\n",
    "        if dot_min != 0 or dot_max != 1:\n",
    "            fracs_values = (fracs_legends - dot_min) / old_range\n",
    "        else:\n",
    "            fracs_values = fracs_legends\n",
    "        size = (fracs_values * 35) ** 1.5\n",
    "        size_legend = fig.add_subplot(axs3[0])\n",
    "        size_legend.scatter(np.repeat(0, len(size)), range(len(size)), s=size, c='blue')\n",
    "        size_legend.set_yticks(range(len(size)))\n",
    "        labels = [\"{:.0%}\".format(x) for x in fracs_legends]\n",
    "        if dot_max < 1:\n",
    "            labels[-1] = \">\" + labels[-1]\n",
    "        size_legend.set_yticklabels(labels)\n",
    "        size_legend.set_yticklabels([\"{:.0%}\".format(x) for x in fracs_legends])\n",
    "        size_legend.tick_params(axis='y', left=False, labelleft=False, labelright=True)\n",
    "        size_legend.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "        size_legend.spines['right'].set_visible(False)\n",
    "        size_legend.spines['top'].set_visible(False)\n",
    "        size_legend.spines['left'].set_visible(False)\n",
    "        size_legend.spines['bottom'].set_visible(False)\n",
    "        size_legend.grid(False)\n",
    "        ymin, ymax = size_legend.get_ylim()\n",
    "        size_legend.set_ylim(ymin, ymax + 0.5)\n",
    "        fig.savefig(save_as, bbox_inches='tight')\n",
    "\n",
    "        return diagcm, xticksactual, axs\n",
    "\n",
    "N_SC_Non=sc.read_h5ad('/public3/home/m6s000666/wanglin/single_cell/LP_LGN/N_LP_LGN_Non_subclass.h5ad')\n",
    "D_SC_Non=sc.read_h5ad('/public3/home/m6s000666/wanglin/single_cell/LP_LGN/D_LP_LGN_Non_subclass.h5ad')\n",
    "\n",
    "del N_SC_Non.obs['cluster']\n",
    "del D_SC_Non.obs['cluster']\n",
    "N_SC_Non.obs['cluster']=N_SC_Non.obs['cluster_use']\n",
    "D_SC_Non.obs['cluster']=D_SC_Non.obs['cluster_use']\n",
    "\n",
    "N_SC_dict = {'Oligo A':0,'Oligo B':1,'Oligo C':2,'Oligo D':3,'Astro A':4,'Astro B':5,'OPC A':6,'Microglia A':7,'VLMC A':8,'Peri A':9}\n",
    "\n",
    "D_SC_dict = {'Oligo 1':0,'Oligo 2':1,'Oligo 4':2,'Oligo 3':3, 'Astro 1':4,'Astro 2':5,'OPC 1':6,'Microglia 1':7,'VLMC 1':8,'Peri 1':9}\n",
    "tm = TimeMapping()\n",
    "validation_label_train_NRvsDR, valid_predlabels_train_NRvsDR, test_labelsNRvsDR, test_predlabelsNRvsDR = tm.xgbclassifier(\n",
    "    train_anndata = N_SC_Non,\n",
    "    test_anndata = D_SC_Non,\n",
    "    train_dict = N_SC_dict,\n",
    "    test_dict = D_SC_dict)\n",
    "mappingconfmatNRvsDR, mappingxticksNRvsDR, mappingplotNRvsDR = tm.plotConfusionMatrix(\n",
    "    ytrue=test_labelsNRvsDR,\n",
    "    ypred=test_predlabelsNRvsDR,\n",
    "    type='mapping',\n",
    "     save_as = 'LP_LGN_Non_cluster_mapping.svg',\n",
    "     title = 'ARI = {:.3f}, NCE = {:.3f}'.format(adjusted_rand_score(labels_true = test_labelsNRvsDR, labels_pred = test_predlabelsNRvsDR), calculateNCE(labels_true = test_labelsNRvsDR, labels_pred = test_predlabelsNRvsDR)),\n",
    "    xaxislabel='NR_LP_LGN_Non_cluster',\n",
    "    yaxislabel='DR_LP_LGN_Non_cluster')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
